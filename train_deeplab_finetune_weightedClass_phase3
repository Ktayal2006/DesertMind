import os
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large
from torch.amp import autocast, GradScaler
from dataset import OffroadSegDataset

torch.backends.cudnn.benchmark = True


# -------------------------
# Metrics
# -------------------------
@torch.no_grad()
def compute_miou(pred, target, num_classes):
    ious = []
    for cls in range(num_classes):
        pred_i = (pred == cls)
        target_i = (target == cls)
        inter = (pred_i & target_i).sum().item()
        union = (pred_i | target_i).sum().item()
        if union > 0:
            ious.append(inter / union)
    return float(np.mean(ious)) if ious else 0.0


@torch.no_grad()
def compute_per_class_iou(pred, target, num_classes):
    out = {}
    for cls in range(num_classes):
        pred_i = (pred == cls)
        target_i = (target == cls)
        inter = (pred_i & target_i).sum().item()
        union = (pred_i | target_i).sum().item()
        out[cls] = None if union == 0 else (inter / union)
    return out


@torch.no_grad()
def pixel_accuracy(pred, target):
    return (pred == target).float().mean().item()


# -------------------------
# Dice Loss
# -------------------------
def dice_loss_from_logits(logits, target, num_classes, eps=1e-6):
    probs = torch.softmax(logits, dim=1)
    target_1h = torch.zeros_like(probs).scatter_(
        1, target.unsqueeze(1), 1.0
    )

    dims = (0, 2, 3)
    inter = (probs * target_1h).sum(dims)
    denom = (probs + target_1h).sum(dims)
    dice = (2 * inter + eps) / (denom + eps)
    return 1.0 - dice.mean()


# -------------------------
# Class Weights
# -------------------------
def compute_class_weights_from_dataset(train_ds, num_classes=10):
    counts = np.zeros(num_classes, dtype=np.float64)

    for _, mask in train_ds:
        m = mask.numpy().reshape(-1)
        for c in range(num_classes):
            counts[c] += np.sum(m == c)

    freqs = counts / counts.sum()
    weights = 1.0 / np.log(1.02 + freqs)
    weights = weights / weights.mean()
    return torch.tensor(weights, dtype=torch.float32)


# -------------------------
# Freeze BatchNorm
# -------------------------
def freeze_bn(module):
    if isinstance(module, nn.BatchNorm2d):
        module.eval()


def main():
    # ================= CONFIG =================
    ROOT = r"C:\Users\DELL\Downloads\Offroad_Segmentation_Training_Dataset\Offroad_Segmentation_Training_Dataset"
    NUM_CLASSES = 10
    BATCH_SIZE = 2
    EPOCHS = 12
    PATIENCE = 3

    LR_BACKBONE = 1e-5
    LR_HEAD = 5e-5

    USE_DICE = True
    DICE_WEIGHT = 0.5

    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    SAVE_PATH = "best_deeplab_balanced.pth"

    print("Using device:", DEVICE)

    # ================= DATA =================
    train_ds = OffroadSegDataset(ROOT, split="train", crop_size=512)
    val_ds = OffroadSegDataset(ROOT, split="val", crop_size=512)

    train_loader = DataLoader(
        train_ds,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=2,
        pin_memory=True,
        persistent_workers=True,
        drop_last=True
    )

    val_loader = DataLoader(
        val_ds,
        batch_size=1,
        shuffle=False,
        num_workers=2,
        pin_memory=True,
        persistent_workers=True
    )

    print("Train size:", len(train_ds), "Val size:", len(val_ds))

    # ================= MODEL =================
    model = deeplabv3_mobilenet_v3_large(weights="DEFAULT")
    model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)
    model.to(DEVICE)

    model.apply(freeze_bn)

    # ================= LOAD CHECKPOINT =================
    best_miou = -1.0
    if os.path.exists(SAVE_PATH):
        model.load_state_dict(torch.load(SAVE_PATH, map_location=DEVICE))
        print(f"Loaded checkpoint: {SAVE_PATH}")

    # ================= LOSS =================
    print("Computing class weights (one-time)...")
    class_weights = compute_class_weights_from_dataset(
        train_ds, NUM_CLASSES
    ).to(DEVICE)
    print("Class weights:", class_weights.cpu().numpy())

    ce_loss = nn.CrossEntropyLoss(weight=class_weights)

    # ================= OPTIMIZER =================
    backbone_params = []
    head_params = []

    for name, p in model.named_parameters():
        if not p.requires_grad:
            continue
        if name.startswith("backbone"):
            backbone_params.append(p)
        else:
            head_params.append(p)

    optimizer = torch.optim.AdamW(
        [
            {"params": backbone_params, "lr": LR_BACKBONE},
            {"params": head_params, "lr": LR_HEAD},
        ],
        weight_decay=1e-4
    )

    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode="max", factor=0.5, patience=1, verbose=True
    )

    scaler = GradScaler("cuda")
    epochs_without_improvement = 0

    # ================= TRAIN =================
    for epoch in range(1, EPOCHS + 1):
        model.train()
        model.apply(freeze_bn)
        train_loss = 0.0

        for imgs, masks in train_loader:
            imgs = imgs.to(DEVICE, non_blocking=True)
            masks = masks.to(DEVICE, non_blocking=True)

            optimizer.zero_grad(set_to_none=True)

            with autocast(device_type="cuda"):
                logits = model(imgs)["out"]
                loss = ce_loss(logits, masks)
                if USE_DICE:
                    loss += DICE_WEIGHT * dice_loss_from_logits(
                        logits, masks, NUM_CLASSES
                    )

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            train_loss += loss.item()

        train_loss /= len(train_loader)

        # ================= VALIDATION =================
        model.eval()
        val_losses = []
        val_ious = []
        per_class_ious = []
        pixel_accs = []

        with torch.no_grad():
            for imgs, masks in val_loader:
                imgs = imgs.to(DEVICE, non_blocking=True)
                masks = masks.to(DEVICE, non_blocking=True)

                with autocast(device_type="cuda"):
                    logits = model(imgs)["out"]
                    vloss = ce_loss(logits, masks)
                    if USE_DICE:
                        vloss += DICE_WEIGHT * dice_loss_from_logits(
                            logits, masks, NUM_CLASSES
                        )

                pred = torch.argmax(logits, dim=1)

                pixel_accs.append(pixel_accuracy(pred, masks))
                val_losses.append(vloss.item())
                val_ious.append(
                    compute_miou(pred.cpu(), masks.cpu(), NUM_CLASSES)
                )
                per_class_ious.append(
                    compute_per_class_iou(pred.cpu(), masks.cpu(), NUM_CLASSES)
                )

        val_loss = float(np.mean(val_losses))
        val_miou = float(np.mean(val_ious))
        val_pixel_acc = float(np.mean(pixel_accs))

        print(
            f"\nEpoch {epoch}/{EPOCHS} | "
            f"train loss {train_loss:.4f} | "
            f"val loss {val_loss:.4f} | "
            f"val mIoU {val_miou:.4f} | "
            f"pixel acc {val_pixel_acc:.4f}"
        )

        print("Per-class IoU:")
        for cls in range(NUM_CLASSES):
            values = [x[cls] for x in per_class_ious if x[cls] is not None]
            if values:
                print(f"  Class {cls}: {sum(values)/len(values):.4f}")
            else:
                print(f"  Class {cls}: N/A")

        scheduler.step(val_miou)

        if val_miou > best_miou:
            best_miou = val_miou
            epochs_without_improvement = 0
            torch.save(model.state_dict(), SAVE_PATH)
            print("âœ… Saved best model:", best_miou)
        else:
            epochs_without_improvement += 1
            print(f"No improvement for {epochs_without_improvement} epoch(s)")

        if epochs_without_improvement >= PATIENCE:
            print("Early stopping triggered.")
            break

    print("Training done. Best validation mIoU:", best_miou)
    print("Saved to:", SAVE_PATH)


if __name__ == "__main__":
    main()
